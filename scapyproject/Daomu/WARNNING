2020-08-03 16:16:55 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:16:55 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:16:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:16:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:16:55 [scrapy.extensions.telnet] INFO: Telnet Password: 97a15cf33622018b
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:16:55 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:16:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:16:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:16:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:16:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:16:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25850,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.156707,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 16, 57, 825075),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 16, 55, 668368)}
2020-08-03 16:16:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:17:26 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:17:26 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:17:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:17:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:17:26 [scrapy.extensions.telnet] INFO: Telnet Password: 46431a7b0f6e6a91
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:17:26 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:17:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:17:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:17:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:17:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:17:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25851,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.173361,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 17, 29, 72646),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 17, 26, 899285)}
2020-08-03 16:17:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:18:52 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:18:52 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:18:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:18:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:18:52 [scrapy.extensions.telnet] INFO: Telnet Password: c204e46f1d6ef610
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:18:52 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:18:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:18:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:18:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:18:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:18:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25850,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.334018,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 18, 53, 938067),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 18, 52, 604049)}
2020-08-03 16:18:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:19:42 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:19:42 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:19:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:19:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:19:42 [scrapy.extensions.telnet] INFO: Telnet Password: abdf4dd0d59bbaf3
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:19:42 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:19:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:19:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:19:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:19:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:52 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-08-03 16:19:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-08-03 16:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2384,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 199785,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 11.24663,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 19, 54, 148330),
 'log_count/DEBUG': 10,
 'log_count/ERROR': 9,
 'log_count/INFO': 11,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 9,
 'start_time': datetime.datetime(2020, 8, 3, 8, 19, 42, 901700)}
2020-08-03 16:19:54 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-08-03 16:20:31 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:20:31 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:20:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:20:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:20:31 [scrapy.extensions.telnet] INFO: Telnet Password: 74dd4081981e0104
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:20:31 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:20:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:20:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:46 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:20:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2872,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 234560,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'elapsed_time_seconds': 14.978274,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 20, 46, 904779),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 11,
 'start_time': datetime.datetime(2020, 8, 3, 8, 20, 31, 926505)}
2020-08-03 16:20:46 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:26:30 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:26:30 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:26:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:26:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:26:30 [scrapy.extensions.telnet] INFO: Telnet Password: 0d8d3ac905034220
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:26:30 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:26:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:26:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:26:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:26:33 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:26:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:26:35 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:26:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 4.507892,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 26, 35, 375812),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 26, 30, 867920)}
2020-08-03 16:26:35 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:27:13 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:27:13 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:27:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:27:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:27:13 [scrapy.extensions.telnet] INFO: Telnet Password: 29425e42a2a359ba
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:27:13 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:27:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:27:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:27:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:27:16 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:27:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:27:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:27:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:27:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 3.694649,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 27, 17, 679051),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 27, 13, 984402)}
2020-08-03 16:27:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:28:21 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:28:21 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:28:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:28:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:28:21 [scrapy.extensions.telnet] INFO: Telnet Password: 35c5c9d2a56bbb3d
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:28:21 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:28:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:28:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:28:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:28:24 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:28:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:28:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:28:25 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:28:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 4.260641,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 28, 25, 331251),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 28, 21, 70610)}
2020-08-03 16:28:25 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:28:48 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:28:48 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:28:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:28:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:28:48 [scrapy.extensions.telnet] INFO: Telnet Password: 9ce33ba2890fb8b1
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:28:48 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:28:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:28:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:28:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:28:50 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:28:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:28:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:28:51 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:28:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 3.299285,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 28, 51, 814560),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 28, 48, 515275)}
2020-08-03 16:28:51 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:29:19 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:29:19 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:29:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:29:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:29:19 [scrapy.extensions.telnet] INFO: Telnet Password: 5be325a29952f1a2
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:29:19 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:29:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:29:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:29:20 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:29:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:29:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:29:21 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:29:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.844452,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 29, 21, 959659),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 29, 19, 115207)}
2020-08-03 16:29:21 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:29:55 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:29:55 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:29:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:29:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:29:55 [scrapy.extensions.telnet] INFO: Telnet Password: 06297299d75fd7c2
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:29:55 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:29:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:29:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:29:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:29:57 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:29:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:29:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:29:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:29:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.515086,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 29, 58, 419752),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 29, 55, 904666)}
2020-08-03 16:29:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:31:47 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:31:47 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:31:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:31:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:31:47 [scrapy.extensions.telnet] INFO: Telnet Password: 501263e458a00647
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:31:47 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:31:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:31:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:31:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:31:48 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:31:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:31:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:31:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.847935,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 31, 49, 976954),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 31, 47, 129019)}
2020-08-03 16:31:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:32:42 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:32:42 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:32:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:32:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:32:42 [scrapy.extensions.telnet] INFO: Telnet Password: 6bbbc73047a45c86
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:32:42 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:32:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:32:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:32:43 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:32:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 16:32:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸',
 'title': '盗墓笔记1：七星鲁王'}
2020-08-03 16:32:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:32:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 5.654398,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 32, 47, 975113),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 8, 32, 42, 320715)}
2020-08-03 16:32:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 17:37:28 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 17:37:28 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 17:37:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 17:37:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 17:37:28 [scrapy.extensions.telnet] INFO: Telnet Password: ea18d3b57c5ae3f0
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 17:37:28 [scrapy.core.engine] INFO: Spider opened
2020-08-03 17:37:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 17:37:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 17:37:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 17:37:31 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 17:37:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 17:37:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 17:37:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸',
 'title': '盗墓笔记1：七星鲁王'}
2020-08-03 17:37:33 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 17:37:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 5.24834,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 9, 37, 33, 950115),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 9, 37, 28, 701775)}
2020-08-03 17:37:33 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 17:48:21 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 17:48:21 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 17:48:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 17:48:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 17:48:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4cc60baa72216db8
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 17:48:21 [scrapy.core.engine] INFO: Spider opened
2020-08-03 17:48:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 17:48:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 17:48:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 17:48:23 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 17:48:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 17:48:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 17:48:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸',
 'title': '盗墓笔记1：七星鲁王'}
2020-08-03 17:48:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 17:48:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 8.014697,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 9, 48, 29, 796400),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 9, 48, 21, 781703)}
2020-08-03 17:48:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:07:02 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:07:02 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:07:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:07:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:07:02 [scrapy.extensions.telnet] INFO: Telnet Password: caad31a3e8cd6ffd
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:07:02 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:07:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:07:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:07:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:07:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:07:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:07:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:07:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸',
 'title': '盗墓笔记1：七星鲁王'}
2020-08-03 18:07:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:07:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96260,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 6.304946,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 7, 9, 234088),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 7, 2, 929142)}
2020-08-03 18:07:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:19:01 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:19:01 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:19:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:19:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:19:01 [scrapy.extensions.telnet] INFO: Telnet Password: 4f226e9ee312985c
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:19:01 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:19:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:19:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:19:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:19:03 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:19:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:19:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:19:06 [scrapy.core.scraper] ERROR: Error processing {'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/pipelines.py", line 13, in process_item
    directory = '/home/davis/myproject/novel/{}/'.format(item['title'])
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 93, in __getitem__
    return self._values[key]
KeyError: 'title'
2020-08-03 18:19:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:19:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96260,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 4.971348,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 19, 6, 619243),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 19, 1, 647895)}
2020-08-03 18:19:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:19:12 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:19:12 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:19:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:19:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:19:12 [scrapy.extensions.telnet] INFO: Telnet Password: 1348cea9a9fea44a
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:19:12 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:19:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:19:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:19:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:19:14 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:19:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:19:17 [scrapy.core.scraper] ERROR: Error processing {'content': '\u3000\u300050年前，长沙镖子岭。\n'
            '\u3000\u3000四个土夫子正蹲在一个土丘上，所有人都不说话，直勾勾地盯着地上那把洛阳铲。\n'
            '\u3000\u3000铲子头上带着刚从地下带出的旧土，离奇的是，这一坏土正不停地向外渗着鲜红的液体，就像刚刚在血液里蘸过一样。\n'
            '\u3000\u3000'
            '“这下子麻烦大喽。”老烟头把他的旱烟在地上敲了敲，接着道，“下面是个血尸嘎，弄不好我们这点儿当当，都要撂在下面噢。”\n'
            '\u3000\u3000'
            '“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说，“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”\n'
            '\u3000\u3000'
            '老烟头不怒反笑，对边上的一个大胡子说：“你屋里二伢子海式撩天的，指不定什么时候就给翻盖子了，你得多教育教育，咱这买卖，不是有只匣子炮就能喔荷西天。”\n'
            '\u3000\u3000'
            '那大胡子瞪了那年轻人一眼：“你崽子，怎么这么跟老太爷讲话，老太爷淘土的时候你他妈的还在你娘肚子里吃屎咧。”\n'
            '\u3000\u3000“我咋说……说错了，老祖宗不说了嘛，那血尸就是个好东西，下面宝贝肯定不少，不下去，走嘎一炉锅汤。”\n'
            '\u3000\u3000“你还敢顶嘴！”大胡子举手就打，被老烟头用烟枪挡了回去。\n'
            '\u3000\u3000“打不得，你做伢那时候不还是一样，这叫上梁不正下梁歪！”\n'
            '\u3000\u3000'
            '那独眼的小伙子看他老爸被数落了，低下头偷笑，老烟头咳嗽了一声，又敲了那独眼的少年一记头棍：“你笑个啥？碰到血尸，可大可小，上次你二公就是在洛阳挖到这东西，结果现在还疯疯癫癫的，都不知道着了什么道。等一下我先下去，你跟在我后面，二伢子你带个土耗子殿后，三伢子你就别下去了，四个人都下去，想退都来不及退，你就拉着土耗子的尾巴，我们在里面一吆喝你就把东西拉出来。”\n'
            '\u3000\u3000年纪最小的那少年不服气了：“我不依，你们偏心，我告诉我娘去！”\n'
            '\u3000\u3000老烟头大笑：“你看你看，三伢子还怯不得子了，别闹，等一下给你摸把金刀刀。”\n'
            '\u3000\u3000“我不要你摸，我自己会摸。”\n'
            '\u3000\u3000那独眼老二就火了，一把揪住老三的耳朵：“你这杂家伙跟我寻事觅缝啰，招呼老子发宝气喃？！” \n'
            '\u3000\u3000'
            '那年纪最小的少年看样子平日挨过不少揍，一看他二哥真火了，就吓得不敢吭声了，直望着他爹求救，怎料他爹已经去收拾家伙去了。他二哥这下得意了：“你何什咯样不带爱相啰，这次老头子也不帮你，你要再吆喝，我拧你个花麻鸡吧！” \n'
            '\u3000\u3000老烟头拍拍老二的肩膀，大叫一声：“小子们，操家伙啰！”说完一把旋风铲已经舞开了。 \n'
            '\u3000\u3000'
            '半个小时候后，盗洞已经打得见不到底了，除了老二不时上来透气，洞里连声音都听不清楚了，老三等得不耐烦起来，就朝洞里大叫：“大爷爷，挖穿没有？”\n'
            '\u3000\u3000隔了有好几秒，里面才传来一阵模糊的声音：“不……知道，你……待在上面，拉好……好绳子！”\n'
            '\u3000\u3000是他二哥的声音，然后听到他那老烟头咳嗽了一声：“轻点声……听！有动静！”\n'
            '\u3000\u3000然后就是死一般的沉寂。\n'
            '\u3000\u3000'
            '老三知道下面肯定有什么变故，吓得也不敢说话了，突然他听到一阵让人毛骨悚然的咯咯声，好像蛤蟆叫一样的从洞里发出来。\n'
            '\u3000\u3000然后他二哥在下面大吼了一声：“三伢子，拉！”\n'
            '\u3000\u3000'
            '他不敢怠慢，一蹬地猛地拽住土耗子的尾巴，就往外拉，刚拉了几下，突然下面好像有什么东西咬住了，竟然有一股反力把绳子向盗洞里拉去，老三根本没想过还会有这种情况，差点就被拉到洞里去，他急中生智，一下子把尾巴绑在自己腰上，然后全身向后倒去，后背几乎和地面成了30度角，这个是他在村里和别的男孩子拔河的时候用的招数，这样一来他的体重就全部吃在绳子上，就算是匹骡子，他也能顶一顶。\n'
            '\u3000\u3000'
            '果然，这样一来他就和洞里的东西对峙住了，双方都各自吃力，但是都拉不动分毫，僵持了有十几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”就觉得绳子一松，土耗子嗖一声从洞里弹了出来，好像上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！\n'
            '\u3000\u3000'
            '他一口七跑出有二里多地，才敢停下来，掏出他怀里的土耗子一看，吓得大叫了一声，原来土耗子上勾着一只血淋淋的断手。他认得那手的模样，不由哭了出来，这手是分明是他二哥的。看样子他二哥就算不死也残废了。想到这里，他不由一咬牙，想回去救他二哥和老爹，刚一回头，却看见背后蹲着个血红血红的东西，正直勾勾地看着他。\n'
            '\u3000\u3000'
            '这老三也不是个二流货色，平日里跟着他老爹大浪淘沙，离奇的事情见过不少，知道这地底下的，什么事情都有可能发生，最重要的不是大惊小怪，而是随机应变，要知道再凶险的鬼也强不过一活人，这什么黑凶白凶的，也得遵守物理定律，一梭子子弹打过去，打烂了也就没什么好怕的了。\n'
            '\u3000\u3000'
            '想到这里，他把心一横，一边后退，一边腰上别着的一支匣子炮已经拽在手里，开了连发，只要那血红的东西有什么动静，就先给他劈头来个暴雨梨花。谁知道这时候那血红的东西竟然站起来了，老三仔细一看，顿觉得头皮发麻，胃里一阵翻腾，那分明是一个被剥了皮的人！混身上下血淋淋的，好像是自己整个儿从人皮里挤了出来一样。可是这样的一个人，竟然还能走动，那真是奇迹了，难道这就是血尸的真面目？\n'
            '\u3000\u3000'
            '想着，那血尸一个弓身，突然就扑了过来，一下子老三就和他对上眼了，那血淋淋的脸一下子就贴着他的鼻子，一股酸气扑面而来，老三顺势向后一倒，同时匣子炮整一梭子子弹全部近距离打在了那东西胸膛上，距离过近，子弹全部都穿了过去，把那东西打的血花四溅，向后退了好几步。老三心中暗喜，再一回手对准那东西的脑袋就一扣扳机，就听喀嚓一声，枪竟然卡壳了！\n'
            '\u3000\u3000'
            '这把老匣子炮是当年他二爷爷从一个军阀墓里挖出来的，想来也没用了多少年月，可惜这几年跟着他爹爹到处跑，也没工夫保养，平时候开枪的机会也少之又少，谁知道竟然在这节骨眼上卡壳了。那老三也真不简单，一看枪不好使唤，轮圆了胳膊用吃奶的力气把枪给砸了过去，也不管砸没砸到，扭头就跑。这次他连头也不敢回，看准前面一颗大树就奔了过去，寻思着怎么着它也不会爬树吧，突然脚下一绊，他一个狗吃屎，整张脸磕在一树墩上，顿时鼻子嘴巴里全是血。\n'
            '\u3000\u3000老三狠狠一巴掌拍在地上，心里那个气啊，妈的怎么就这么背。\n'
            '\u3000\u3000'
            '这时候听到后面风声响起，知道阎王爷来点名了，心一横，死就死吧，索性就趴在地上不起来了。没成想，那具血尸好像没看到他一样，竟然从他身上踩了过去，那血淋淋的脚板马上在他背后印下一个印子，这血尸出奇的重，一脚下去，老三就觉得嗓子一甜，只觉胆汁都被像踩吐了出来，而且背上那被踩过地方马上一阵奇痒，眼前马上朦胧起来，他马上意识到自己可能中毒了，而且毒性还非常的猛烈，恍惚间他看到不远处的地方，他二哥的那只手里好像还握着什么东西。\n'
            '\u3000\u3000'
            '他用力眨了眨眼睛，仔细一看，原来是一块古帛片。他心想，自家二哥拼了命都要带出来的东西，肯定不是寻常东西，现在又不知道他们怎么样了，我好歹得把东西收好，万一我真的死了，他们找到我的尸体，也能从我身上找得着，那二哥的这只手也不算白断了，我也不至于白死。他一边这么想着，一边艰难地爬过去，用力掰开二哥紧握的手把那帛片从掌心里拿出来，塞进了自己袖子里。\n'
            '\u3000\u3000'
            '这个时候他的耳朵也开始蜂鸣了，眼睛就像蒙了一层纱一样，手脚都开始凉起来。按他以往的经验，现在他裤裆里肯定大小便一大堆，中尸毒的人都死得很难看，他现在最希望的是不要给隔壁村的二丫头看见自己这个样子。\n'
            '\u3000\u3000他就这么混混着胡想，脑子已经不怎么听他使唤了，这时候他又开始隐隐约约地听到他在盗洞口听到的那种咯咯怪声。\n'
            '\u3000\u3000'
            '老三隐约觉得一丝不对，刚才和血尸搏斗了这么些时候，也没听它叫过一声，现在怎么又叫起来了？难道刚才的那只并不是血尸？那刚才看到的又是什么东西呢？可惜这个时候他已经基本无法做思考了，他条件反射地抬起头看了一下，只见一张巨大的怪脸正俯下身子看着他，两只没有瞳孔的眼睛里空荡荡地毫无生气。',
 'name': '七星鲁王 第一章 血尸'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/pipelines.py", line 13, in process_item
    directory = '/home/davis/myproject/novel/{}/'.format(item['title'])
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 93, in __getitem__
    return self._values[key]
KeyError: 'title'
2020-08-03 18:19:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:19:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96262,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 4.946129,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 19, 17, 166618),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 19, 12, 220489)}
2020-08-03 18:19:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:21:11 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:21:11 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:21:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:21:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:21:11 [scrapy.extensions.telnet] INFO: Telnet Password: ad5588fce5d9be1f
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:21:11 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:21:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:21:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:21:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:21:13 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:21:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 34, in parse_two_page
    item['two_link'] = article.xpath('//article/a/@href').get()
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'DaomuItem does not support field: two_link'
2020-08-03 18:21:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:21:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.65125,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 21, 14, 431198),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 10, 21, 11, 779948)}
2020-08-03 18:21:14 [scrapy.core.engine] INFO: Spider closed (finished)
