2020-08-03 16:16:55 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:16:55 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:16:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:16:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:16:55 [scrapy.extensions.telnet] INFO: Telnet Password: 97a15cf33622018b
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:16:55 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:16:55 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:16:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:16:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:16:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:16:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:16:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25850,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.156707,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 16, 57, 825075),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 16, 55, 668368)}
2020-08-03 16:16:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:17:26 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:17:26 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:17:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:17:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:17:26 [scrapy.extensions.telnet] INFO: Telnet Password: 46431a7b0f6e6a91
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:17:26 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:17:26 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:17:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:17:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:17:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:17:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:17:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25851,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.173361,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 17, 29, 72646),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 17, 26, 899285)}
2020-08-03 16:17:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:18:52 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:18:52 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:18:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:18:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:18:52 [scrapy.extensions.telnet] INFO: Telnet Password: c204e46f1d6ef610
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:18:52 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:18:52 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:18:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:18:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:18:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:18:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:18:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 194,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 25850,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.334018,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 18, 53, 938067),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 18, 52, 604049)}
2020-08-03 16:18:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:19:42 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:19:42 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:19:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:19:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:19:42 [scrapy.extensions.telnet] INFO: Telnet Password: abdf4dd0d59bbaf3
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:19:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:19:42 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:19:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:19:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:19:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:19:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:52 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-08-03 16:19:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-08-03 16:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
2020-08-03 16:19:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:19:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2384,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 199785,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 11.24663,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 19, 54, 148330),
 'log_count/DEBUG': 10,
 'log_count/ERROR': 9,
 'log_count/INFO': 11,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 9,
 'start_time': datetime.datetime(2020, 8, 3, 8, 19, 42, 901700)}
2020-08-03 16:19:54 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-08-03 16:20:31 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:20:31 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:20:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:20:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:20:31 [scrapy.extensions.telnet] INFO: Telnet Password: 74dd4081981e0104
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:20:31 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:20:31 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:20:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:20:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/zang-hai-hua> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/sha-hai> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2015> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-8> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-7> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-6> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-5> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-4> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-3> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-2> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-2> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:20:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:20:46 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:20:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2872,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 234560,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'elapsed_time_seconds': 14.978274,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 20, 46, 904779),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 11,
 'start_time': datetime.datetime(2020, 8, 3, 8, 20, 31, 926505)}
2020-08-03 16:20:46 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:26:30 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:26:30 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:26:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:26:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:26:30 [scrapy.extensions.telnet] INFO: Telnet Password: 0d8d3ac905034220
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:26:30 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:26:30 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:26:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:26:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:26:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:26:33 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:26:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:26:35 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:26:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 4.507892,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 26, 35, 375812),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 26, 30, 867920)}
2020-08-03 16:26:35 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:27:13 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:27:13 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:27:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:27:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:27:13 [scrapy.extensions.telnet] INFO: Telnet Password: 29425e42a2a359ba
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:27:13 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:27:13 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:27:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:27:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:27:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:27:16 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:27:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:27:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:27:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:27:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 3.694649,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 27, 17, 679051),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 27, 13, 984402)}
2020-08-03 16:27:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:28:21 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:28:21 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:28:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:28:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:28:21 [scrapy.extensions.telnet] INFO: Telnet Password: 35c5c9d2a56bbb3d
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:28:21 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:28:21 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:28:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:28:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:28:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:28:24 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:28:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:28:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 38, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:28:25 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:28:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 4.260641,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 28, 25, 331251),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 28, 21, 70610)}
2020-08-03 16:28:25 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:28:48 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:28:48 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:28:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:28:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:28:48 [scrapy.extensions.telnet] INFO: Telnet Password: 9ce33ba2890fb8b1
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:28:48 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:28:48 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:28:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:28:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:28:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:28:50 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:28:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:28:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:28:51 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:28:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 3.299285,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 28, 51, 814560),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 28, 48, 515275)}
2020-08-03 16:28:51 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:29:19 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:29:19 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:29:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:29:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:29:19 [scrapy.extensions.telnet] INFO: Telnet Password: 5be325a29952f1a2
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:29:19 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:29:19 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:29:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:29:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:29:20 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:29:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:29:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:29:21 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:29:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.844452,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 29, 21, 959659),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 29, 19, 115207)}
2020-08-03 16:29:21 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:29:55 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:29:55 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:29:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:29:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:29:55 [scrapy.extensions.telnet] INFO: Telnet Password: 06297299d75fd7c2
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:29:55 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:29:55 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:29:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:29:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:29:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:29:57 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:29:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:29:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:29:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:29:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.515086,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 29, 58, 419752),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 29, 55, 904666)}
2020-08-03 16:29:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:31:47 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:31:47 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:31:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:31:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:31:47 [scrapy.extensions.telnet] INFO: Telnet Password: 501263e458a00647
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:31:47 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:31:47 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:31:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:31:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:31:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:31:48 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:31:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 39, in parse_two_page
    callback=self.parse_three_page
AttributeError: 'DaomuSpider' object has no attribute 'parse_three_page'
2020-08-03 16:31:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:31:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.847935,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 31, 49, 976954),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 8, 31, 47, 129019)}
2020-08-03 16:31:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 16:32:42 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 16:32:42 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 16:32:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 16:32:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 16:32:42 [scrapy.extensions.telnet] INFO: Telnet Password: 6bbbc73047a45c86
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 16:32:42 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 16:32:42 [scrapy.core.engine] INFO: Spider opened
2020-08-03 16:32:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 16:32:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 16:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 16:32:43 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 16:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 16:32:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 16:32:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  ',
 'title': '1'}
2020-08-03 16:32:47 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 16:32:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 5.654398,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 8, 32, 47, 975113),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1595555840,
 'memusage/startup': 1595555840,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 8, 32, 42, 320715)}
2020-08-03 16:32:47 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 17:37:28 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 17:37:28 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 17:37:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 17:37:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 17:37:28 [scrapy.extensions.telnet] INFO: Telnet Password: ea18d3b57c5ae3f0
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 17:37:28 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 17:37:28 [scrapy.core.engine] INFO: Spider opened
2020-08-03 17:37:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 17:37:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 17:37:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 17:37:31 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 17:37:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 17:37:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 17:37:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  ',
 'title': '1'}
2020-08-03 17:37:33 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 17:37:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 5.24834,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 9, 37, 33, 950115),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 9, 37, 28, 701775)}
2020-08-03 17:37:33 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 17:48:21 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 17:48:21 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 17:48:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 17:48:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 17:48:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4cc60baa72216db8
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 17:48:21 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 17:48:21 [scrapy.core.engine] INFO: Spider opened
2020-08-03 17:48:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 17:48:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 17:48:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 17:48:23 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 17:48:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 17:48:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 17:48:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  ',
 'title': '1'}
2020-08-03 17:48:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 17:48:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96261,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 8.014697,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 9, 48, 29, 796400),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 9, 48, 21, 781703)}
2020-08-03 17:48:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:07:02 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:07:02 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:07:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:07:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:07:02 [scrapy.extensions.telnet] INFO: Telnet Password: caad31a3e8cd6ffd
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:07:02 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:07:02 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:07:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:07:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:07:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:07:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:07:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:07:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:07:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.daomubiji.com/qi-xing-lu-wang-01.html>
{'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  ',
 'title': '1'}
2020-08-03 18:07:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:07:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96260,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 6.304946,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 7, 9, 234088),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 7, 2, 929142)}
2020-08-03 18:07:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:19:01 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:19:01 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:19:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:19:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:19:01 [scrapy.extensions.telnet] INFO: Telnet Password: 4f226e9ee312985c
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:19:01 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:19:01 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:19:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:19:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:19:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:19:03 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:19:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:19:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:19:06 [scrapy.core.scraper] ERROR: Error processing {'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  '}
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/pipelines.py", line 13, in process_item
    directory = '/home/davis/myproject/novel/{}/'.format(item['title'])
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 93, in __getitem__
    return self._values[key]
KeyError: 'title'
2020-08-03 18:19:06 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:19:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96260,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 4.971348,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 19, 6, 619243),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 19, 1, 647895)}
2020-08-03 18:19:06 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:19:12 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:19:12 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:19:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:19:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:19:12 [scrapy.extensions.telnet] INFO: Telnet Password: 1348cea9a9fea44a
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:19:12 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:19:12 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:19:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:19:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:19:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:19:14 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:19:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:19:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/qi-xing-lu-wang-01.html> (referer: http://www.daomubiji.com/dao-mu-bi-ji-1)
2020-08-03 18:19:17 [scrapy.core.scraper] ERROR: Error processing {'content': '\u3000\u300050\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            ' \n'
            '\u3000\u3000 \n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '30\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000'
            '\n'
            '\u3000\u3000\n'
            '\u3000\u3000'
            '',
 'name': '  '}
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/pipelines.py", line 13, in process_item
    directory = '/home/davis/myproject/novel/{}/'.format(item['title'])
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 93, in __getitem__
    return self._values[key]
KeyError: 'title'
2020-08-03 18:19:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:19:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 705,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 96262,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 84,
 'elapsed_time_seconds': 4.946129,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 19, 17, 166618),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 8, 3, 10, 19, 12, 220489)}
2020-08-03 18:19:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-08-03 18:21:11 [scrapy.utils.log] INFO: Scrapy 2.2.1 started (bot: Daomu)
2020-08-03 18:21:11 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.5.2 (default, Jul 17 2020, 14:04:10) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.0, Platform Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
2020-08-03 18:21:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-08-03 18:21:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Daomu',
 'CONCURRENT_REQUESTS': 3,
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'WARNNING',
 'NEWSPIDER_MODULE': 'Daomu.spiders',
 'SPIDER_MODULES': ['Daomu.spiders']}
2020-08-03 18:21:11 [scrapy.extensions.telnet] INFO: Telnet Password: ad5588fce5d9be1f
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 18:21:11 [scrapy.middleware] INFO: Enabled item pipelines:
['Daomu.pipelines.DaomuPipeline']
2020-08-03 18:21:11 [scrapy.core.engine] INFO: Spider opened
2020-08-03 18:21:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 18:21:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 18:21:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/> (referer: None)
2020-08-03 18:21:13 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.daomubiji.com/dao-mu-bi-ji-1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-03 18:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
2020-08-03 18:21:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.daomubiji.com/dao-mu-bi-ji-1> (referer: http://www.daomubiji.com/)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/utils/python.py", line 346, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.5/dist-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/davis/myproject/stage05-WangWeiChao/scapyproject/Daomu/Daomu/spiders/daomu.py", line 34, in parse_two_page
    item['two_link'] = article.xpath('//article/a/@href').get()
  File "/usr/local/lib/python3.5/dist-packages/scrapy/item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'DaomuItem does not support field: two_link'
2020-08-03 18:21:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 18:21:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 438,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 44380,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 2.65125,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 10, 21, 14, 431198),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 1597984768,
 'memusage/startup': 1597984768,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 8, 3, 10, 21, 11, 779948)}
2020-08-03 18:21:14 [scrapy.core.engine] INFO: Spider closed (finished)
